{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c164e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "root_path = rootutils.setup_root(\".\", indicator=\".project-root\", pythonpath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff5759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257, # Vocabulary size\n",
    " \"context_length\": 1024, # Context length\n",
    " \"emb_dim\": 768, # Embedding dimension\n",
    " \"n_heads\": 12, # Number of attention heads\n",
    " \"n_layers\": 12, # Number of layers\n",
    " \"dropout\": 0.1, # Dropout rate\n",
    " \"qvk_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d9a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42bd0d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0053,  0.0976, -0.1119,  ...,  1.2888,  0.2626,  0.6683],\n",
       "         [ 0.0028, -0.2366,  0.1721,  ...,  0.5953,  0.2498,  0.7447],\n",
       "         [ 0.4675,  0.4470,  0.1792,  ...,  1.2521,  0.3048,  0.7748],\n",
       "         [ 0.0664,  0.7225,  0.9206,  ...,  0.4790,  0.7428,  0.7014]],\n",
       "\n",
       "        [[ 0.3623,  1.2142,  0.5221,  ...,  0.1853,  0.0114, -0.5029],\n",
       "         [-0.0224,  0.7787,  0.2769,  ...,  0.1735,  0.5418,  0.1144],\n",
       "         [ 0.7427,  0.4012,  0.3209,  ...,  0.3268,  0.7522, -0.1639],\n",
       "         [ 0.5743,  0.6240,  0.4408,  ...,  1.1961,  1.2648,  0.2242]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f07034cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0195322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fd2fbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.emb_layer.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba6ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05ce086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20ab81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0476,  0.3486,  0.3194,  ...,  0.1212, -0.0145,  0.2356],\n",
       "         [ 0.6108, -1.0272,  0.7170,  ...,  0.8626,  0.3677, -0.1301],\n",
       "         [-0.1292, -0.3700,  0.0999,  ..., -0.3548, -0.6217, -0.1343],\n",
       "         [-0.7753, -0.0209,  0.2924,  ..., -0.2467,  0.5945, -0.5021]],\n",
       "\n",
       "        [[-0.2779,  0.0502,  0.9543,  ...,  0.1103,  0.4312,  0.0555],\n",
       "         [-0.3889, -1.0040,  0.6679,  ...,  0.4921,  0.0253, -0.8168],\n",
       "         [-0.5116, -1.2918,  0.8687,  ..., -0.6738, -0.5146,  0.2423],\n",
       "         [-1.0213, -0.5296, -0.0295,  ...,  0.3974, -0.2751, -0.7770]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8069c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96802726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) #2 passo\n",
    " \n",
    "        logits = logits[:, -1, :] # (batch, n_token, vocab_size) ->(batch_size, vocab_size)  # 3 passo\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1) # 4 passo, convertendo para probabilidades\n",
    "\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True) # 5 passo, pegando o indice do token mais provavel\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # 6 passo, concatenando o indice do token mais provavel com o contexto\n",
    "\n",
    "    return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17e5ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 616, 1545]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, my friend\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30478929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(model=model,idx=encoded_tensor,max_new_tokens=10, context_size=GPT_CONFIG_124M[\"context_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e681167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   616,  1545, 44684,  6759, 39602, 33753,  2126, 46260,\n",
      "         16911, 46633,   400, 25329]])\n",
      "Output length: 14\n",
      "Out shape: torch.Size([1, 14])\n"
     ]
    }
   ],
   "source": [
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n",
    "print(\"Out shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a102a511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my friend Vargmat Rout Ober ideacorruptionomas 372thumbles'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68dc0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tokens_ids(text, tokenizer):\n",
    "    encoded_text = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded_text).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(tokens_ids, tokenizer):\n",
    "    flat = tokens_ids.squeeze(0)\n",
    "    text = tokenizer.decode(flat.tolist())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50c4c3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   616,  1545]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_tokens_ids(start_context, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4344210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, how are you?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(text_to_tokens_ids(\"Hello, how are you?\", tokenizer), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73e62a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, my friend Vargmat Rout Ober ideacorruptionomas 372thumbles'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(out, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e5f1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],[40, 1107, 588]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "791ba6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345 ], [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "651a396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7477374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d821f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0523e-05, 1.5334e-05, 3.3921e-05,  ..., 1.9002e-05,\n",
       "          3.3693e-05, 2.2031e-05],\n",
       "         [2.5165e-05, 5.3138e-06, 3.1071e-05,  ..., 3.1750e-05,\n",
       "          2.2444e-05, 9.2135e-06],\n",
       "         [1.7155e-05, 9.1176e-06, 2.2495e-05,  ..., 1.0265e-05,\n",
       "          8.0308e-06, 1.3215e-05]],\n",
       "\n",
       "        [[2.5355e-05, 3.5654e-05, 3.1680e-05,  ..., 1.9384e-05,\n",
       "          1.8915e-05, 1.5493e-05],\n",
       "         [3.7725e-05, 1.4277e-05, 3.9441e-05,  ..., 4.6905e-05,\n",
       "          2.1555e-05, 1.1217e-05],\n",
       "         [9.2747e-06, 4.8651e-06, 4.1455e-05,  ..., 2.1042e-05,\n",
       "          1.2174e-05, 3.1666e-05]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim=-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdbdc2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7822559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16833,  3626,  6100],\n",
       "        [   40,  1107,   588]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a645a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2107],\n",
       "         [32179],\n",
       "         [16402]],\n",
       "\n",
       "        [[ 6017],\n",
       "         [13489],\n",
       "         [30643]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids  = torch.argmax(probs, dim = -1, keepdim = True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08398af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2107],\n",
       "        [32179],\n",
       "        [16402]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9a018ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  livehzPO\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    " f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a089f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 2:  really like chocolate\n",
      "Outputs batch 2: alty spottedIFIC\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 2: {token_ids_to_text(targets[1], tokenizer)}\")\n",
    "print(f\"Outputs batch 2:\"\n",
    " f\" {token_ids_to_text(token_ids[1].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2059f020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.9085e-06, 1.3188e-05, 1.1656e-05])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_idx  = 0\n",
    "target_probas_1 = probs[text_idx, [0,1,2] ,targets[text_idx]]\n",
    "target_probas_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05f41257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1aaab976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1107,   588, 11311])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[text_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b15aa4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d1e250b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2733e-05, 3.6689e-05, 1.1817e-05])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_idx  = 1\n",
    "target_probas_2 = probs[text_idx, [0,1,2] ,targets[text_idx]]\n",
    "target_probas_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "314ce9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2733e-05)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[1, 0 ,1107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c0c5f0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0523e-05, 1.5334e-05, 3.3921e-05,  ..., 1.9002e-05,\n",
       "          3.3693e-05, 2.2031e-05],\n",
       "         [2.5165e-05, 5.3138e-06, 3.1071e-05,  ..., 3.1750e-05,\n",
       "          2.2444e-05, 9.2135e-06],\n",
       "         [1.7155e-05, 9.1176e-06, 2.2495e-05,  ..., 1.0265e-05,\n",
       "          8.0308e-06, 1.3215e-05]],\n",
       "\n",
       "        [[2.5355e-05, 3.5654e-05, 3.1680e-05,  ..., 1.9384e-05,\n",
       "          1.8915e-05, 1.5493e-05],\n",
       "         [3.7725e-05, 1.4277e-05, 3.9441e-05,  ..., 4.6905e-05,\n",
       "          2.1555e-05, 1.1217e-05],\n",
       "         [9.2747e-06, 4.8651e-06, 4.1455e-05,  ..., 2.1042e-05,\n",
       "          1.2174e-05, 3.1666e-05]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim=-1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0a1dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.view(-1, logits.shape[-1])\n",
    "logits_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d01e7beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_flat = targets.view(-1)\n",
    "target_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26daac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3626,  6100,   345,  1107,   588, 11311])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "95081907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "064830d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2182)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, target_flat)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b4552a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2182)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "log_probs = F.log_softmax(logits_flat, dim=-1)  # [6, 50257]\n",
    "target_log_probs = log_probs[torch.arange(logits_flat.shape[0]), target_flat]  # [6]\n",
    "loss_manual = -target_log_probs.mean()\n",
    "loss_manual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
