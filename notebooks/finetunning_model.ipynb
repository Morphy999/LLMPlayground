{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c829b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rootutils\n",
    "root_path = rootutils.setup_root(\".\", indicator=\".project-root\", pythonpath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3bedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e83891ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file_path = r\"C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Data\\SMSSpamCollection\"\n",
    "\n",
    "df = pd.read_csv(\n",
    " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_data(df):\n",
    "\n",
    "    spam_df = df[df[\"Label\"] == \"spam\"]\n",
    "    \n",
    "    num_spam = len(spam_df)\n",
    "\n",
    "\n",
    "    ham_df = df[df[\"Label\"] == \"ham\"]\n",
    "\n",
    "\n",
    "    ham_df = ham_df.sample(num_spam)\n",
    "\n",
    "\n",
    "    balanced_df = pd.concat([spam_df, ham_df]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd1b394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>0</td>\n",
       "      <td>Jus finish my lunch on my way home lor... I to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>0</td>\n",
       "      <td>All day working day:)except saturday and sunday..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>0</td>\n",
       "      <td>R we still meeting 4 dinner tonight?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>0</td>\n",
       "      <td>Yeah work is fine, started last week, all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>0</td>\n",
       "      <td>Wat makes some people dearer is not just de ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "0         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1         1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "2         1  WINNER!! As a valued network customer you have...\n",
       "3         1  Had your mobile 11 months or more? U R entitle...\n",
       "4         1  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "...     ...                                                ...\n",
       "1489      0  Jus finish my lunch on my way home lor... I to...\n",
       "1490      0  All day working day:)except saturday and sunday..\n",
       "1491      0               R we still meeting 4 dinner tonight?\n",
       "1492      0  Yeah work is fine, started last week, all the ...\n",
       "1493      0  Wat makes some people dearer is not just de ha...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = create_balanced_data(df)\n",
    "balanced_df['Label'] = balanced_df['Label'].map({'spam': 1, 'ham': 0})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec96fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_ratio = 0.7, validation_ratio = 0.1):\n",
    "\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    train_size = int(len(df) * train_ratio)\n",
    "\n",
    "    validation_size = int(len(df) * validation_ratio) \n",
    "\n",
    "    df_train = df.iloc[:train_size]\n",
    "    df_validation = df.iloc[train_size:train_size + validation_size]\n",
    "    df_test = df.iloc[train_size + validation_size:]\n",
    "\n",
    "    return df_train, df_validation, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf818609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_validation, df_test = random_split(balanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a89d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data.dataset import SMSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336c769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2412be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f60e5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Text']  = df_train['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2b04c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       U have a secret admirer who is looking 2 make ...\n",
       "1       We tried to contact you re your reply to our o...\n",
       "2                            I donno if they are scorable\n",
       "3       No shit, but I wasn't that surprised, so I wen...\n",
       "4            No messages on her phone. I'm holding it now\n",
       "                              ...                        \n",
       "1040    I'm home. Doc gave me pain meds says everythin...\n",
       "1041    I want to send something that can sell fast.  ...\n",
       "1042                  U WILL SWITCH YOUR FONE ON DAMMIT!!\n",
       "1043          Now project pa. After that only i can come.\n",
       "1044    BIG BROTHER ALERT! The computer has selected u...\n",
       "Name: Text, Length: 1045, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22cff34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52,\n",
       " 423,\n",
       " 257,\n",
       " 3200,\n",
       " 21099,\n",
       " 81,\n",
       " 508,\n",
       " 318,\n",
       " 2045,\n",
       " 362,\n",
       " 787,\n",
       " 2800,\n",
       " 351,\n",
       " 471,\n",
       " 12,\n",
       " 19796,\n",
       " 503,\n",
       " 508,\n",
       " 484,\n",
       " 371,\n",
       " 9,\n",
       " 36955,\n",
       " 282,\n",
       " 508,\n",
       " 6834,\n",
       " 37902,\n",
       " 523,\n",
       " 2041,\n",
       " 12,\n",
       " 13345,\n",
       " 319,\n",
       " 7769,\n",
       " 2713,\n",
       " 34583,\n",
       " 2231,\n",
       " 5824]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(df_train['Text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4ca00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SMSDataset(df_train, tokenizer, max_length = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97139149",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "from core.data.dataset import SMSDataset\n",
    "from core.data.dataloader import create_dataloader_sms\n",
    "\n",
    "train_dataset = SMSDataset(df_train, tokenizer)\n",
    "\n",
    "validation_dataset = SMSDataset(df_validation, tokenizer, max_length=train_dataset.max_length)\n",
    "\n",
    "test_dataset = SMSDataset(df_test, tokenizer, max_length=train_dataset.max_length)\n",
    "\n",
    "train_loader = create_dataloader_sms(train_dataset, batch_size, num_workers=num_workers)\n",
    "\n",
    "validation_loader = create_dataloader_sms(validation_dataset, batch_size, num_workers=num_workers)\n",
    "\n",
    "test_loader = create_dataloader_sms(test_dataset, batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20510d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    " \"vocab_size\": 50257,\n",
    " \"context_length\": 1024,\n",
    " \"dropout\": 0.0,\n",
    " \"qvk_bias\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "475c5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fbd858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6d57256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'dropout': 0.0,\n",
       " 'qvk_bias': True,\n",
       " 'emb_dim': 768,\n",
       " 'n_layers': 12,\n",
       " 'n_heads': 12}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "BASE_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ef9c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEXT = \"Every effort moves\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc89f307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from core.models.gpt import GPTModel\n",
    "\n",
    "from core.data.utils import load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    " model_size=model_size, models_dir=r\"C:\\Users\\WalterBuenodeBritoNe\\Documents\\GitHub\\LLMPlayground\\Weigths\\gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b402cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (emb_layer): Embedding(50257, 768)\n",
       "  (pos_emb_layer): Embedding(1024, 768)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer_blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (attn_layer): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff_layer): FeedForward(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm_layer1): LayerNorm()\n",
       "      (norm_layer2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be35436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
